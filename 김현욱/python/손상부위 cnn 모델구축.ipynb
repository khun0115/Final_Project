{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khun0115/Final_Project/blob/khun0115/Final(car_damage).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wLyhK268wAd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input, concatenate\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow.keras.utils as utils\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras.applications import Xception, ResNet50, InceptionV3, MobileNet\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.initializers import he_normal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lEmdyRi85GU",
        "outputId": "dba32443-8686-4cc0-8be6-78aa971f84e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdirve\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdirve')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZLxPAV29vj0"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR = \"/content\"\n",
        "DATA_ROOT_DIR = os.path.join(ROOT_DIR, \"car_damage_type_5569\")\n",
        "\n",
        "shutil.copy(os.path.join(\"/content/gdirve/MyDrive/FINAL PROJECT\" , \"car_damage_type_5569.zip\"), ROOT_DIR)\n",
        "\n",
        "with zipfile.ZipFile(os.path.join(ROOT_DIR, \"car_damage_type_5569.zip\"), \"r\") as target_file:\n",
        "    target_file.extractall(DATA_ROOT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N11mw6XLctCl"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR = \"/content\"\n",
        "DATA_ROOT_DIR = os.path.join(ROOT_DIR, \"car_damage_type_5569\")\n",
        "\n",
        "IMG_WIDTH = 100\n",
        "IMG_HEIGHT = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssz_4Mnnmh9B"
      },
      "outputs": [],
      "source": [
        "DATADATA_ROOT_DIR = os.path.join(DATA_ROOT_DIR,\"car_damage_type\")\n",
        "\n",
        "TRAIN_DATA_ROOT_DIR = os.path.join(DATADATA_ROOT_DIR,\"train\")\n",
        "TEST_DATA_ROOT_DIR = os.path.join(DATADATA_ROOT_DIR,'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScHlAgFTq0Pf"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(100, 100, 3),\n",
        "                 padding=\"SAME\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(100, 100, 3),\n",
        "                 padding=\"SAME\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding=\"SAME\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "                 padding=\"SAME\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(100, 100, 3),\n",
        "                 padding=\"SAME\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding=\"SAME\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(64, 64, 3),\n",
        "                 padding=\"SAME\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding=\"SAME\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(4, activation=\"softmax\"))  # 두 번째 Dense 레이어의 크기를 10으로 설정\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_57IIDvbuhPe"
      },
      "outputs": [],
      "source": [
        "start_time = datetime.now()\n",
        "\n",
        "result = model.fit(train_generator, epochs= 100, validation_data=test_generator)\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(\"걸린시간 : \", end_time-start_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS4GwH38qeHy"
      },
      "source": [
        "# inceptionv3 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYlPc-6EDlL3"
      },
      "outputs": [],
      "source": [
        "pre_model = pre_trained_model = InceptionV3(weights = \"imagenet\", include_top=False,\n",
        "                             input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "\n",
        "pre_trained_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuqDkoVQqrLf",
        "outputId": "b3711c72-6bd2-4151-cec2-355693068b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_v3 (Functional)   (None, 1, 1, 2048)        21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                131136    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,951,076\n",
            "Trainable params: 21,916,644\n",
            "Non-trainable params: 34,432\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(pre_trained_model)\n",
        "\n",
        "model.add(GlobalAveragePooling2D())  # Flatten 대신 사용\n",
        "\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(4, activation=\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "             optimizer=Adam(1e-5), metrics = [\"acc\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iRaQK0JsQDB",
        "outputId": "193ff6f3-79db-4824-cd5d-14198144ac38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "557/557 [==============================] - 251s 381ms/step - loss: 1.4127 - acc: 0.2674 - val_loss: 1.3700 - val_acc: 0.3576\n",
            "Epoch 2/30\n",
            "557/557 [==============================] - 210s 377ms/step - loss: 1.3471 - acc: 0.2985 - val_loss: 1.3450 - val_acc: 0.3735\n",
            "Epoch 3/30\n",
            "557/557 [==============================] - 209s 376ms/step - loss: 1.2948 - acc: 0.3684 - val_loss: 1.3972 - val_acc: 0.3769\n",
            "Epoch 4/30\n",
            "557/557 [==============================] - 208s 373ms/step - loss: 1.2628 - acc: 0.3994 - val_loss: 1.7110 - val_acc: 0.3747\n",
            "Epoch 5/30\n",
            "557/557 [==============================] - 209s 375ms/step - loss: 1.2349 - acc: 0.4160 - val_loss: 1.4986 - val_acc: 0.3717\n",
            "Epoch 6/30\n",
            "557/557 [==============================] - 211s 379ms/step - loss: 1.2093 - acc: 0.4282 - val_loss: 1.5280 - val_acc: 0.3747\n",
            "Epoch 7/30\n",
            "557/557 [==============================] - 212s 381ms/step - loss: 1.1921 - acc: 0.4301 - val_loss: 2.2377 - val_acc: 0.3749\n",
            "Epoch 8/30\n",
            "557/557 [==============================] - 208s 374ms/step - loss: 1.1791 - acc: 0.4345 - val_loss: 1.4286 - val_acc: 0.3693\n",
            "Epoch 9/30\n",
            "557/557 [==============================] - 208s 374ms/step - loss: 1.1630 - acc: 0.4401 - val_loss: 1.7094 - val_acc: 0.3738\n",
            "Epoch 10/30\n",
            "557/557 [==============================] - 209s 374ms/step - loss: 1.1533 - acc: 0.4441 - val_loss: 1.5931 - val_acc: 0.3753\n",
            "Epoch 11/30\n",
            "557/557 [==============================] - 208s 374ms/step - loss: 1.1369 - acc: 0.4494 - val_loss: 1.5407 - val_acc: 0.3677\n",
            "Epoch 12/30\n",
            "557/557 [==============================] - 208s 373ms/step - loss: 1.1255 - acc: 0.4474 - val_loss: 1.7142 - val_acc: 0.3695\n",
            "Epoch 13/30\n",
            "557/557 [==============================] - 209s 374ms/step - loss: 1.1116 - acc: 0.4493 - val_loss: 2.0054 - val_acc: 0.3657\n",
            "Epoch 14/30\n",
            "557/557 [==============================] - 208s 374ms/step - loss: 1.1086 - acc: 0.4475 - val_loss: 1.3805 - val_acc: 0.3760\n",
            "Epoch 15/30\n",
            "557/557 [==============================] - 209s 375ms/step - loss: 1.1051 - acc: 0.4489 - val_loss: 2.0396 - val_acc: 0.3715\n",
            "Epoch 16/30\n",
            "557/557 [==============================] - 209s 375ms/step - loss: 1.0913 - acc: 0.4635 - val_loss: 2.6304 - val_acc: 0.3702\n",
            "Epoch 17/30\n",
            "557/557 [==============================] - 213s 383ms/step - loss: 1.0793 - acc: 0.4550 - val_loss: 1.5992 - val_acc: 0.3722\n",
            "Epoch 18/30\n",
            "557/557 [==============================] - 209s 375ms/step - loss: 1.0786 - acc: 0.4615 - val_loss: 1.9292 - val_acc: 0.3652\n",
            "Epoch 19/30\n",
            "557/557 [==============================] - 209s 376ms/step - loss: 1.0649 - acc: 0.4553 - val_loss: 1.5391 - val_acc: 0.3681\n",
            "Epoch 20/30\n",
            "557/557 [==============================] - 209s 375ms/step - loss: 1.0579 - acc: 0.4612 - val_loss: 1.5384 - val_acc: 0.3664\n",
            "Epoch 21/30\n",
            "557/557 [==============================] - 210s 377ms/step - loss: 1.0517 - acc: 0.4636 - val_loss: 2.0624 - val_acc: 0.3693\n",
            "Epoch 22/30\n",
            "557/557 [==============================] - 209s 375ms/step - loss: 1.0358 - acc: 0.4629 - val_loss: 3.3238 - val_acc: 0.3702\n",
            "Epoch 23/30\n",
            "557/557 [==============================] - 209s 375ms/step - loss: 1.0328 - acc: 0.4561 - val_loss: 2.1283 - val_acc: 0.3659\n",
            "Epoch 24/30\n",
            "557/557 [==============================] - 209s 375ms/step - loss: 1.0286 - acc: 0.4680 - val_loss: 1.5268 - val_acc: 0.3668\n",
            "Epoch 25/30\n",
            "557/557 [==============================] - 209s 375ms/step - loss: 1.0169 - acc: 0.4638 - val_loss: 2.5701 - val_acc: 0.3632\n",
            "Epoch 26/30\n",
            "557/557 [==============================] - 208s 374ms/step - loss: 1.0099 - acc: 0.4704 - val_loss: 1.6398 - val_acc: 0.3648\n",
            "Epoch 27/30\n",
            "557/557 [==============================] - 199s 358ms/step - loss: 1.0073 - acc: 0.4703 - val_loss: 1.5892 - val_acc: 0.3639\n",
            "Epoch 28/30\n",
            "557/557 [==============================] - 205s 369ms/step - loss: 0.9971 - acc: 0.4652 - val_loss: 1.4696 - val_acc: 0.3646\n",
            "Epoch 29/30\n",
            "557/557 [==============================] - 201s 361ms/step - loss: 0.9910 - acc: 0.4740 - val_loss: 1.8926 - val_acc: 0.3639\n",
            "Epoch 30/30\n",
            "557/557 [==============================] - 199s 358ms/step - loss: 0.9912 - acc: 0.4718 - val_loss: 1.6461 - val_acc: 0.3639\n"
          ]
        }
      ],
      "source": [
        "start_time = datetime.now()\n",
        "\n",
        "result = model.fit(train_generator, epochs= 30, validation_data=test_generator)\n",
        "\n",
        "end_time = datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNyRYvc0sb1A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK2hvjGoBiNT"
      },
      "source": [
        "# Mobile Net 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eclbXVRPBhjU",
        "outputId": "235458b6-bc84-464c-de6d-301dfbd22336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mobilenet_1.00_224\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 50, 50, 32)        864       \n",
            "                                                                 \n",
            " conv1_bn (BatchNormalizatio  (None, 50, 50, 32)       128       \n",
            " n)                                                              \n",
            "                                                                 \n",
            " conv1_relu (ReLU)           (None, 50, 50, 32)        0         \n",
            "                                                                 \n",
            " conv_dw_1 (DepthwiseConv2D)  (None, 50, 50, 32)       288       \n",
            "                                                                 \n",
            " conv_dw_1_bn (BatchNormaliz  (None, 50, 50, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_1_relu (ReLU)       (None, 50, 50, 32)        0         \n",
            "                                                                 \n",
            " conv_pw_1 (Conv2D)          (None, 50, 50, 64)        2048      \n",
            "                                                                 \n",
            " conv_pw_1_bn (BatchNormaliz  (None, 50, 50, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_1_relu (ReLU)       (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " conv_pad_2 (ZeroPadding2D)  (None, 51, 51, 64)        0         \n",
            "                                                                 \n",
            " conv_dw_2 (DepthwiseConv2D)  (None, 25, 25, 64)       576       \n",
            "                                                                 \n",
            " conv_dw_2_bn (BatchNormaliz  (None, 25, 25, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_2_relu (ReLU)       (None, 25, 25, 64)        0         \n",
            "                                                                 \n",
            " conv_pw_2 (Conv2D)          (None, 25, 25, 128)       8192      \n",
            "                                                                 \n",
            " conv_pw_2_bn (BatchNormaliz  (None, 25, 25, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_2_relu (ReLU)       (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_3 (DepthwiseConv2D)  (None, 25, 25, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_3_bn (BatchNormaliz  (None, 25, 25, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_3_relu (ReLU)       (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_3 (Conv2D)          (None, 25, 25, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_3_bn (BatchNormaliz  (None, 25, 25, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_3_relu (ReLU)       (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " conv_pad_4 (ZeroPadding2D)  (None, 26, 26, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_4 (DepthwiseConv2D)  (None, 12, 12, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_4_bn (BatchNormaliz  (None, 12, 12, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_4_relu (ReLU)       (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_4 (Conv2D)          (None, 12, 12, 256)       32768     \n",
            "                                                                 \n",
            " conv_pw_4_bn (BatchNormaliz  (None, 12, 12, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_4_relu (ReLU)       (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " conv_dw_5 (DepthwiseConv2D)  (None, 12, 12, 256)      2304      \n",
            "                                                                 \n",
            " conv_dw_5_bn (BatchNormaliz  (None, 12, 12, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_5_relu (ReLU)       (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " conv_pw_5 (Conv2D)          (None, 12, 12, 256)       65536     \n",
            "                                                                 \n",
            " conv_pw_5_bn (BatchNormaliz  (None, 12, 12, 256)      1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_5_relu (ReLU)       (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " conv_pad_6 (ZeroPadding2D)  (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " conv_dw_6 (DepthwiseConv2D)  (None, 6, 6, 256)        2304      \n",
            "                                                                 \n",
            " conv_dw_6_bn (BatchNormaliz  (None, 6, 6, 256)        1024      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_6_relu (ReLU)       (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv_pw_6 (Conv2D)          (None, 6, 6, 512)         131072    \n",
            "                                                                 \n",
            " conv_pw_6_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_6_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_7 (DepthwiseConv2D)  (None, 6, 6, 512)        4608      \n",
            "                                                                 \n",
            " conv_dw_7_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_7_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_7 (Conv2D)          (None, 6, 6, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_7_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_7_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_8 (DepthwiseConv2D)  (None, 6, 6, 512)        4608      \n",
            "                                                                 \n",
            " conv_dw_8_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_8_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_8 (Conv2D)          (None, 6, 6, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_8_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_8_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_9 (DepthwiseConv2D)  (None, 6, 6, 512)        4608      \n",
            "                                                                 \n",
            " conv_dw_9_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_9_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_9 (Conv2D)          (None, 6, 6, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_9_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_9_relu (ReLU)       (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_10 (DepthwiseConv2D  (None, 6, 6, 512)        4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_10_bn (BatchNormali  (None, 6, 6, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_10_relu (ReLU)      (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_10 (Conv2D)         (None, 6, 6, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_10_bn (BatchNormali  (None, 6, 6, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_10_relu (ReLU)      (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_11 (DepthwiseConv2D  (None, 6, 6, 512)        4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_11_bn (BatchNormali  (None, 6, 6, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_11_relu (ReLU)      (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_11 (Conv2D)         (None, 6, 6, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_11_bn (BatchNormali  (None, 6, 6, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_11_relu (ReLU)      (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv_pad_12 (ZeroPadding2D)  (None, 7, 7, 512)        0         \n",
            "                                                                 \n",
            " conv_dw_12 (DepthwiseConv2D  (None, 3, 3, 512)        4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_12_bn (BatchNormali  (None, 3, 3, 512)        2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_12_relu (ReLU)      (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_12 (Conv2D)         (None, 3, 3, 1024)        524288    \n",
            "                                                                 \n",
            " conv_pw_12_bn (BatchNormali  (None, 3, 3, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_12_relu (ReLU)      (None, 3, 3, 1024)        0         \n",
            "                                                                 \n",
            " conv_dw_13 (DepthwiseConv2D  (None, 3, 3, 1024)       9216      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_13_bn (BatchNormali  (None, 3, 3, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_13_relu (ReLU)      (None, 3, 3, 1024)        0         \n",
            "                                                                 \n",
            " conv_pw_13 (Conv2D)         (None, 3, 3, 1024)        1048576   \n",
            "                                                                 \n",
            " conv_pw_13_bn (BatchNormali  (None, 3, 3, 1024)       4096      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_13_relu (ReLU)      (None, 3, 3, 1024)        0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,228,864\n",
            "Trainable params: 3,206,976\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "pre_model = pre_trained_model = MobileNet(weights = \"imagenet\", include_top=False,\n",
        "                             input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krWuLAJuBhmA",
        "outputId": "5df6ef58-7425-488b-81c5-cb107c1d4175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenet_1.00_224 (Functio  (None, 3, 3, 1024)       3228864   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1024)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                65600     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,294,724\n",
            "Trainable params: 3,272,836\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(pre_trained_model)\n",
        "\n",
        "model.add(GlobalAveragePooling2D())  # Flatten 대신 사용\n",
        "\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(4, activation=\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "             optimizer=Adam(1e-5), metrics = [\"acc\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dUAN1OjuBhoV",
        "outputId": "eca33884-f89a-4b1f-b9da-1bd320dbc9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "557/557 [==============================] - 248s 390ms/step - loss: 2.0282 - acc: 0.3039 - val_loss: 1.3989 - val_acc: 0.3949\n",
            "Epoch 2/50\n",
            "557/557 [==============================] - 216s 388ms/step - loss: 1.5531 - acc: 0.3771 - val_loss: 1.2657 - val_acc: 0.4459\n",
            "Epoch 3/50\n",
            "557/557 [==============================] - 221s 397ms/step - loss: 1.3429 - acc: 0.4247 - val_loss: 1.2002 - val_acc: 0.4766\n",
            "Epoch 4/50\n",
            "557/557 [==============================] - 219s 394ms/step - loss: 1.2389 - acc: 0.4635 - val_loss: 1.1562 - val_acc: 0.5027\n",
            "Epoch 5/50\n",
            "557/557 [==============================] - 218s 391ms/step - loss: 1.1714 - acc: 0.4875 - val_loss: 1.1236 - val_acc: 0.5256\n",
            "Epoch 6/50\n",
            "557/557 [==============================] - 212s 381ms/step - loss: 1.1310 - acc: 0.5128 - val_loss: 1.0935 - val_acc: 0.5481\n",
            "Epoch 7/50\n",
            "557/557 [==============================] - 214s 384ms/step - loss: 1.0872 - acc: 0.5359 - val_loss: 1.0719 - val_acc: 0.5573\n",
            "Epoch 8/50\n",
            "557/557 [==============================] - 213s 382ms/step - loss: 1.0483 - acc: 0.5558 - val_loss: 1.0524 - val_acc: 0.5647\n",
            "Epoch 9/50\n",
            "557/557 [==============================] - 215s 386ms/step - loss: 1.0056 - acc: 0.5760 - val_loss: 1.0362 - val_acc: 0.5746\n",
            "Epoch 10/50\n",
            "557/557 [==============================] - 215s 387ms/step - loss: 0.9653 - acc: 0.5944 - val_loss: 1.0186 - val_acc: 0.5831\n",
            "Epoch 11/50\n",
            "557/557 [==============================] - 218s 391ms/step - loss: 0.9355 - acc: 0.6099 - val_loss: 1.0107 - val_acc: 0.5874\n",
            "Epoch 12/50\n",
            "557/557 [==============================] - 211s 379ms/step - loss: 0.9052 - acc: 0.6310 - val_loss: 1.0014 - val_acc: 0.5928\n",
            "Epoch 13/50\n",
            "557/557 [==============================] - 214s 384ms/step - loss: 0.8743 - acc: 0.6488 - val_loss: 0.9936 - val_acc: 0.5952\n",
            "Epoch 14/50\n",
            "557/557 [==============================] - 226s 406ms/step - loss: 0.8522 - acc: 0.6497 - val_loss: 0.9893 - val_acc: 0.6020\n",
            "Epoch 15/50\n",
            "557/557 [==============================] - 220s 394ms/step - loss: 0.8237 - acc: 0.6652 - val_loss: 0.9854 - val_acc: 0.6053\n",
            "Epoch 16/50\n",
            "557/557 [==============================] - 214s 384ms/step - loss: 0.7836 - acc: 0.6827 - val_loss: 0.9820 - val_acc: 0.6085\n",
            "Epoch 17/50\n",
            "557/557 [==============================] - 213s 383ms/step - loss: 0.7612 - acc: 0.6878 - val_loss: 0.9777 - val_acc: 0.6125\n",
            "Epoch 18/50\n",
            "557/557 [==============================] - 216s 388ms/step - loss: 0.7401 - acc: 0.7023 - val_loss: 0.9711 - val_acc: 0.6087\n",
            "Epoch 19/50\n",
            "557/557 [==============================] - 215s 387ms/step - loss: 0.7175 - acc: 0.7081 - val_loss: 0.9749 - val_acc: 0.6168\n",
            "Epoch 20/50\n",
            "557/557 [==============================] - 215s 386ms/step - loss: 0.6866 - acc: 0.7299 - val_loss: 0.9741 - val_acc: 0.6164\n",
            "Epoch 21/50\n",
            "557/557 [==============================] - 216s 387ms/step - loss: 0.6567 - acc: 0.7419 - val_loss: 0.9766 - val_acc: 0.6155\n",
            "Epoch 22/50\n",
            "557/557 [==============================] - 217s 390ms/step - loss: 0.6344 - acc: 0.7465 - val_loss: 0.9762 - val_acc: 0.6213\n",
            "Epoch 23/50\n",
            "557/557 [==============================] - 217s 390ms/step - loss: 0.6206 - acc: 0.7552 - val_loss: 0.9740 - val_acc: 0.6251\n",
            "Epoch 24/50\n",
            "557/557 [==============================] - 213s 383ms/step - loss: 0.6015 - acc: 0.7645 - val_loss: 0.9866 - val_acc: 0.6190\n",
            "Epoch 25/50\n",
            "557/557 [==============================] - 218s 391ms/step - loss: 0.5772 - acc: 0.7752 - val_loss: 0.9871 - val_acc: 0.6247\n",
            "Epoch 26/50\n",
            "557/557 [==============================] - 214s 385ms/step - loss: 0.5565 - acc: 0.7856 - val_loss: 0.9970 - val_acc: 0.6267\n",
            "Epoch 27/50\n",
            "557/557 [==============================] - 211s 379ms/step - loss: 0.5353 - acc: 0.7902 - val_loss: 1.0047 - val_acc: 0.6262\n",
            "Epoch 28/50\n",
            "557/557 [==============================] - 210s 377ms/step - loss: 0.5175 - acc: 0.8011 - val_loss: 1.0073 - val_acc: 0.6283\n",
            "Epoch 29/50\n",
            "557/557 [==============================] - 212s 381ms/step - loss: 0.4996 - acc: 0.8062 - val_loss: 1.0186 - val_acc: 0.6303\n",
            "Epoch 30/50\n",
            "557/557 [==============================] - 204s 367ms/step - loss: 0.4782 - acc: 0.8168 - val_loss: 1.0246 - val_acc: 0.6274\n",
            "Epoch 31/50\n",
            "557/557 [==============================] - 206s 370ms/step - loss: 0.4527 - acc: 0.8261 - val_loss: 1.0332 - val_acc: 0.6361\n",
            "Epoch 32/50\n",
            "557/557 [==============================] - 208s 373ms/step - loss: 0.4394 - acc: 0.8298 - val_loss: 1.0404 - val_acc: 0.6269\n",
            "Epoch 33/50\n",
            "557/557 [==============================] - 206s 369ms/step - loss: 0.4183 - acc: 0.8434 - val_loss: 1.0553 - val_acc: 0.6296\n",
            "Epoch 34/50\n",
            "  3/557 [..............................] - ETA: 2:27 - loss: 0.4380 - acc: 0.7917"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-733f1e4e5440>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "start_time = datetime.now()\n",
        "\n",
        "result = model.fit(train_generator, epochs= 50, validation_data=test_generator)\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(\"걸린시간 : \", end_time-start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUNBN_jeBhqh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet 사용"
      ],
      "metadata": {
        "id": "9QAvmr0J2EJG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvdco9mCBhsx"
      },
      "outputs": [],
      "source": [
        "pre_model = pre_trained_model = ResNet50(weights = \"imagenet\", include_top=False,\n",
        "                             input_shape = (IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(pre_trained_model)\n",
        "\n",
        "model.add(GlobalAveragePooling2D())  # Flatten 대신 사용\n",
        "\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(4, activation=\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "             optimizer=Adam(1e-5), metrics = [\"acc\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BWkeAbC2f2Y",
        "outputId": "4ceeb697-2af3-41ea-fe19-948639cb23d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                131136    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,723,268\n",
            "Trainable params: 23,670,148\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = datetime.now()\n",
        "\n",
        "result = model.fit(train_generator, epochs= 30, validation_data=test_generator)\n",
        "\n",
        "end_time = datetime.now()\n",
        "print(\"걸린시간 : \", end_time-start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipdINI692pxP",
        "outputId": "c7bb8502-0aac-4bc3-dd60-e1cb6736ad15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "557/557 [==============================] - 304s 462ms/step - loss: 1.7870 - acc: 0.2660 - val_loss: 5.4109 - val_acc: 0.2525\n",
            "Epoch 2/30\n",
            "557/557 [==============================] - 212s 381ms/step - loss: 1.4147 - acc: 0.2976 - val_loss: 1.3259 - val_acc: 0.3500\n",
            "Epoch 3/30\n",
            "557/557 [==============================] - 212s 381ms/step - loss: 1.3452 - acc: 0.3302 - val_loss: 1.2852 - val_acc: 0.4052\n",
            "Epoch 4/30\n",
            "557/557 [==============================] - 212s 381ms/step - loss: 1.2984 - acc: 0.3666 - val_loss: 1.2368 - val_acc: 0.4544\n",
            "Epoch 5/30\n",
            "557/557 [==============================] - 215s 386ms/step - loss: 1.2525 - acc: 0.4034 - val_loss: 1.1933 - val_acc: 0.4847\n",
            "Epoch 6/30\n",
            "557/557 [==============================] - 212s 380ms/step - loss: 1.2020 - acc: 0.4385 - val_loss: 1.1394 - val_acc: 0.5204\n",
            "Epoch 7/30\n",
            "557/557 [==============================] - 211s 379ms/step - loss: 1.1364 - acc: 0.4825 - val_loss: 1.1049 - val_acc: 0.5467\n",
            "Epoch 8/30\n",
            "557/557 [==============================] - 209s 376ms/step - loss: 1.0774 - acc: 0.5188 - val_loss: 1.0709 - val_acc: 0.5699\n",
            "Epoch 9/30\n",
            "557/557 [==============================] - 211s 379ms/step - loss: 1.0105 - acc: 0.5621 - val_loss: 1.0357 - val_acc: 0.5883\n",
            "Epoch 10/30\n",
            "557/557 [==============================] - 215s 385ms/step - loss: 0.9305 - acc: 0.6046 - val_loss: 1.0227 - val_acc: 0.6027\n",
            "Epoch 11/30\n",
            "557/557 [==============================] - 212s 381ms/step - loss: 0.8473 - acc: 0.6433 - val_loss: 1.0323 - val_acc: 0.6071\n",
            "Epoch 12/30\n",
            "557/557 [==============================] - 212s 380ms/step - loss: 0.7620 - acc: 0.6918 - val_loss: 1.0521 - val_acc: 0.6116\n",
            "Epoch 13/30\n",
            "557/557 [==============================] - 213s 382ms/step - loss: 0.6744 - acc: 0.7366 - val_loss: 1.0918 - val_acc: 0.6146\n",
            "Epoch 14/30\n",
            "557/557 [==============================] - 217s 389ms/step - loss: 0.5889 - acc: 0.7739 - val_loss: 1.1619 - val_acc: 0.6177\n",
            "Epoch 15/30\n",
            "557/557 [==============================] - 216s 387ms/step - loss: 0.5246 - acc: 0.8031 - val_loss: 1.1997 - val_acc: 0.6116\n",
            "Epoch 16/30\n",
            "557/557 [==============================] - 216s 388ms/step - loss: 0.4490 - acc: 0.8360 - val_loss: 1.2844 - val_acc: 0.6103\n",
            "Epoch 17/30\n",
            "557/557 [==============================] - 255s 457ms/step - loss: 0.3982 - acc: 0.8592 - val_loss: 1.3517 - val_acc: 0.6065\n",
            "Epoch 18/30\n",
            "557/557 [==============================] - 229s 411ms/step - loss: 0.3332 - acc: 0.8844 - val_loss: 1.4361 - val_acc: 0.6116\n",
            "Epoch 19/30\n",
            "557/557 [==============================] - 229s 412ms/step - loss: 0.2895 - acc: 0.9010 - val_loss: 1.5125 - val_acc: 0.6161\n",
            "Epoch 20/30\n",
            "557/557 [==============================] - 230s 412ms/step - loss: 0.2476 - acc: 0.9195 - val_loss: 1.6032 - val_acc: 0.6083\n",
            "Epoch 21/30\n",
            "557/557 [==============================] - 228s 409ms/step - loss: 0.2162 - acc: 0.9319 - val_loss: 1.6869 - val_acc: 0.6083\n",
            "Epoch 22/30\n",
            "557/557 [==============================] - 226s 406ms/step - loss: 0.1953 - acc: 0.9388 - val_loss: 1.7442 - val_acc: 0.6141\n",
            "Epoch 23/30\n",
            "557/557 [==============================] - 219s 393ms/step - loss: 0.1585 - acc: 0.9533 - val_loss: 1.8212 - val_acc: 0.6157\n",
            "Epoch 24/30\n",
            "557/557 [==============================] - 214s 385ms/step - loss: 0.1495 - acc: 0.9531 - val_loss: 1.9007 - val_acc: 0.6146\n",
            "Epoch 25/30\n",
            "557/557 [==============================] - 209s 375ms/step - loss: 0.1279 - acc: 0.9630 - val_loss: 2.0160 - val_acc: 0.6148\n",
            "Epoch 26/30\n",
            "557/557 [==============================] - 214s 383ms/step - loss: 0.1224 - acc: 0.9657 - val_loss: 2.0373 - val_acc: 0.6179\n",
            "Epoch 27/30\n",
            "557/557 [==============================] - 209s 376ms/step - loss: 0.1132 - acc: 0.9668 - val_loss: 2.0565 - val_acc: 0.6094\n",
            "Epoch 28/30\n",
            "557/557 [==============================] - 213s 382ms/step - loss: 0.1017 - acc: 0.9703 - val_loss: 2.1448 - val_acc: 0.6166\n",
            "Epoch 29/30\n",
            "557/557 [==============================] - 210s 377ms/step - loss: 0.0942 - acc: 0.9734 - val_loss: 2.1905 - val_acc: 0.6159\n",
            "Epoch 30/30\n",
            "557/557 [==============================] - 212s 379ms/step - loss: 0.0923 - acc: 0.9744 - val_loss: 2.1888 - val_acc: 0.6159\n",
            "걸린시간 :  1:53:02.443981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XP9bW2F2rYR",
        "outputId": "461c628e-fe6b-4285-be33-dbe7671b793c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140/140 [==============================] - 39s 278ms/step - loss: 2.1888 - acc: 0.6159\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.188838481903076, 0.6159029603004456]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3KmcrqxVY88"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOzGSIoNYzeonJef3hOt1eQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}